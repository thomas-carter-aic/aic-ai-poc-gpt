training:
  model: "gptx-13b"
  dataset: "mixture_code_heavy"
  epochs: 1
  batch_size: 1
  learning_rate: 1e-4
  max_seq_length: 8192
  optimizer: "adamw"
  rope_scaling: "linear"
