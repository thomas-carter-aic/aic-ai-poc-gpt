# Free-Tier mini-GPT serving container
FROM python:3.11-slim

RUN apt-get update && apt-get install -y git wget && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY ./gptx ./gptx
COPY ./inference ./inference
COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

EXPOSE 8000
ENTRYPOINT ["uvicorn", "inference.server_fastapi:app", "--host", "0.0.0.0", "--port", "8000"]
